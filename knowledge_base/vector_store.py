"""
FAISSå‘é‡å­˜å‚¨
=============
åŸºäºFAISSçš„å‘é‡æ£€ç´¢ï¼Œä½¿ç”¨BGE-large-zh embedding
"""

import os
import json
import numpy as np
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass


@dataclass
class VectorStoreConfig:
    """å‘é‡å­˜å‚¨é…ç½®"""
    model_path: str = "/data/models/bge-large-zh-v1.5"
    index_type: str = "FlatIP"  # å†…ç§¯ï¼Œé…åˆå½’ä¸€åŒ–ç­‰ä»·äºä½™å¼¦ç›¸ä¼¼åº¦
    dimension: int = 1024       # BGE-largeç»´åº¦
    batch_size: int = 32        # ç¼–ç æ‰¹æ¬¡å¤§å°


class VectorStore:
    """
    FAISSå‘é‡å­˜å‚¨
    
    åŠŸèƒ½ï¼š
    - æ¡ˆä¾‹å‘é‡åŒ–å­˜å‚¨
    - ç›¸ä¼¼æ¡ˆä¾‹æ£€ç´¢
    - æ‰¹é‡é‡å»ºç´¢å¼•
    """
    
    def __init__(self, storage_path: str, config: VectorStoreConfig = None):
        """
        åˆå§‹åŒ–å‘é‡å­˜å‚¨
        
        Args:
            storage_path: å­˜å‚¨è·¯å¾„
            config: é…ç½®
        """
        self.storage_path = storage_path
        self.config = config or VectorStoreConfig()
        
        # è·¯å¾„
        self.vectors_path = os.path.join(storage_path, "vectors")
        self.index_file = os.path.join(self.vectors_path, "cases.index")
        self.ids_file = os.path.join(self.vectors_path, "cases_ids.json")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.vectors_path, exist_ok=True)
        
        # å»¶è¿ŸåŠ è½½
        self._model = None
        self._index = None
        self._case_ids = []  # FAISSç´¢å¼•ä½ç½® -> case_idæ˜ å°„
        self._dirty = True   # æ˜¯å¦éœ€è¦é‡å»º
        
        # å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•
        self._load_index()
    
    @property
    def model(self):
        """å»¶è¿ŸåŠ è½½embeddingæ¨¡å‹"""
        if self._model is None:
            print(f"ğŸ“¦ åŠ è½½Embeddingæ¨¡å‹: {self.config.model_path}")
            try:
                from sentence_transformers import SentenceTransformer
                self._model = SentenceTransformer(
                    self.config.model_path,
                    device="cpu"
                )
                print(f"   âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
            except Exception as e:
                print(f"   âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                raise
        return self._model
    
    @property
    def index(self):
        """è·å–FAISSç´¢å¼•"""
        return self._index
    
    @property
    def is_dirty(self):
        """ç´¢å¼•æ˜¯å¦éœ€è¦é‡å»º"""
        return self._dirty
    
    def mark_dirty(self):
        """æ ‡è®°ç´¢å¼•éœ€è¦é‡å»º"""
        self._dirty = True
    
    def _load_index(self):
        """åŠ è½½å·²æœ‰ç´¢å¼•"""
        if os.path.exists(self.index_file) and os.path.exists(self.ids_file):
            try:
                import faiss
                self._index = faiss.read_index(self.index_file)
                with open(self.ids_file, 'r', encoding='utf-8') as f:
                    self._case_ids = json.load(f)
                self._dirty = False
                print(f"ğŸ“‚ åŠ è½½å‘é‡ç´¢å¼•: {len(self._case_ids)}æ¡")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½å‘é‡ç´¢å¼•å¤±è´¥: {e}")
                self._index = None
                self._case_ids = []
                self._dirty = True
    
    def _save_index(self):
        """ä¿å­˜ç´¢å¼•"""
        if self._index is not None:
            import faiss
            faiss.write_index(self._index, self.index_file)
            with open(self.ids_file, 'w', encoding='utf-8') as f:
                json.dump(self._case_ids, f, ensure_ascii=False)
    
    def build_case_text(self, case_data: Dict) -> str:
        """
        æ„å»ºæ¡ˆä¾‹çš„å‘é‡åŒ–æ–‡æœ¬
        
        Args:
            case_data: æ¡ˆä¾‹æ•°æ®ï¼ˆä»JSONåŠ è½½çš„å­—å…¸ï¼‰
        
        Returns:
            ç”¨äºå‘é‡åŒ–çš„æ–‡æœ¬
        """
        parts = []
        
        # åŸºç¡€ä¿¡æ¯
        address = case_data.get('address', {})
        if isinstance(address, dict):
            address = address.get('value', '')
        parts.append(f"åœ°å€ï¼š{address}")
        
        # åŒºåŸŸä¿¡æ¯
        district = case_data.get('district', '')
        if district:
            parts.append(f"åŒºåŸŸï¼š{district}")
        
        street = case_data.get('street', '')
        if street:
            parts.append(f"è¡—é“ï¼š{street}")
        
        # ç”¨é€”
        usage = case_data.get('usage', '')
        if usage:
            parts.append(f"ç”¨é€”ï¼š{usage}")
        
        # ç»“æ„
        structure = case_data.get('structure', '')
        if structure:
            parts.append(f"ç»“æ„ï¼š{structure}")
        
        # é¢ç§¯
        area = case_data.get('building_area', {})
        if isinstance(area, dict):
            area = area.get('value', 0)
        if area:
            parts.append(f"å»ºç­‘é¢ç§¯ï¼š{area}å¹³æ–¹ç±³")
        
        # æ¥¼å±‚
        floor = case_data.get('current_floor', 0)
        total_floor = case_data.get('total_floor', 0)
        if floor and total_floor:
            parts.append(f"æ¥¼å±‚ï¼š{floor}/{total_floor}å±‚")
        elif floor:
            parts.append(f"æ¥¼å±‚ï¼š{floor}å±‚")
        
        # å»ºæˆå¹´ä»½
        build_year = case_data.get('build_year', 0)
        if build_year:
            parts.append(f"å»ºæˆå¹´ä»½ï¼š{build_year}å¹´")
        
        # æœå‘
        orientation = case_data.get('orientation', '')
        if orientation:
            parts.append(f"æœå‘ï¼š{orientation}")
        
        # è£…ä¿®
        decoration = case_data.get('decoration', '')
        if decoration:
            parts.append(f"è£…ä¿®ï¼š{decoration}")
        
        # å› ç´ æè¿°ï¼ˆé‡è¦çš„è¯­ä¹‰ä¿¡æ¯ï¼‰
        for factor_type in ['location_factors', 'physical_factors', 'rights_factors']:
            factors = case_data.get(factor_type, {})
            if isinstance(factors, dict):
                for factor_name, factor_data in factors.items():
                    if isinstance(factor_data, dict):
                        desc = factor_data.get('description', '')
                        if desc and len(desc) > 2:
                            parts.append(desc)
        
        return " ".join(parts)
    
    def encode(self, texts: List[str]) -> np.ndarray:
        """
        æ–‡æœ¬ç¼–ç ä¸ºå‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
        
        Returns:
            å‘é‡æ•°ç»„ (n, dim)
        """
        if not texts:
            return np.array([])
        
        # BGEæ¨¡å‹å»ºè®®æ·»åŠ æŒ‡ä»¤å‰ç¼€
        # å¯¹äºæ£€ç´¢ä»»åŠ¡ï¼ŒqueryåŠ å‰ç¼€ï¼Œpassageä¸åŠ 
        vectors = self.model.encode(
            texts,
            batch_size=self.config.batch_size,
            show_progress_bar=len(texts) > 10,
            normalize_embeddings=True  # å½’ä¸€åŒ–ï¼Œä½¿å†…ç§¯ç­‰ä»·äºä½™å¼¦ç›¸ä¼¼åº¦
        )
        return vectors
    
    def encode_query(self, query: str) -> np.ndarray:
        """
        ç¼–ç æŸ¥è¯¢æ–‡æœ¬ï¼ˆæ·»åŠ BGEæŸ¥è¯¢å‰ç¼€ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
        
        Returns:
            æŸ¥è¯¢å‘é‡ (1, dim)
        """
        # BGEæ¨¡å‹çš„æŸ¥è¯¢å‰ç¼€
        query_with_prefix = f"ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š{query}"
        vector = self.model.encode(
            [query_with_prefix],
            normalize_embeddings=True
        )
        return vector
    
    def rebuild(self, cases: List[Dict]):
        """
        é‡å»ºå‘é‡ç´¢å¼•
        
        Args:
            cases: æ¡ˆä¾‹åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡ˆä¾‹éœ€åŒ…å«case_idå’Œå®Œæ•´æ•°æ®
        """
        import faiss
        
        if not cases:
            print("âš ï¸ æ²¡æœ‰æ¡ˆä¾‹æ•°æ®ï¼Œè·³è¿‡å‘é‡ç´¢å¼•æ„å»º")
            self._index = None
            self._case_ids = []
            self._dirty = False
            return
        
        print(f"ğŸ”¨ é‡å»ºå‘é‡ç´¢å¼•: {len(cases)}ä¸ªæ¡ˆä¾‹")
        
        # æ„å»ºæ–‡æœ¬
        texts = []
        case_ids = []
        for case in cases:
            case_id = case.get('case_id_full') or case.get('case_id')
            if not case_id:
                continue
            
            text = self.build_case_text(case)
            if text.strip():
                texts.append(text)
                case_ids.append(case_id)
        
        if not texts:
            print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ–‡æœ¬ï¼Œè·³è¿‡å‘é‡ç´¢å¼•æ„å»º")
            self._index = None
            self._case_ids = []
            self._dirty = False
            return
        
        # ç¼–ç 
        print(f"   ç¼–ç  {len(texts)} æ¡æ–‡æœ¬...")
        vectors = self.encode(texts)
        
        # åˆ›å»ºç´¢å¼•
        print(f"   æ„å»ºFAISSç´¢å¼•...")
        dimension = vectors.shape[1]
        self._index = faiss.IndexFlatIP(dimension)  # å†…ç§¯ç´¢å¼•
        self._index.add(vectors.astype(np.float32))
        
        self._case_ids = case_ids
        self._dirty = False
        
        # ä¿å­˜
        self._save_index()
        print(f"   âœ“ å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ: {self._index.ntotal}æ¡å‘é‡")
    
    def search(self, 
               query: str, 
               top_k: int = 20,
               filter_ids: List[str] = None) -> List[Tuple[str, float]]:
        """
        å‘é‡æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
            filter_ids: é™å®šåœ¨è¿™äº›IDä¸­æœç´¢ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            [(case_id, score), ...]
        """
        if self._index is None or self._index.ntotal == 0:
            return []
        
        # ç¼–ç æŸ¥è¯¢
        query_vector = self.encode_query(query)
        
        # æœç´¢
        # å¦‚æœæœ‰filter_idsï¼Œæœæ›´å¤šç„¶åè¿‡æ»¤
        search_k = top_k * 3 if filter_ids else top_k
        search_k = min(search_k, self._index.ntotal)
        
        scores, indices = self._index.search(
            query_vector.astype(np.float32), 
            search_k
        )
        
        # ç»„è£…ç»“æœ
        results = []
        for i, idx in enumerate(indices[0]):
            if idx < 0 or idx >= len(self._case_ids):
                continue
            
            case_id = self._case_ids[idx]
            score = float(scores[0][i])
            
            # è¿‡æ»¤
            if filter_ids and case_id not in filter_ids:
                continue
            
            results.append((case_id, score))
            
            if len(results) >= top_k:
                break
        
        return results
    
    def search_by_case(self,
                       case_data: Dict,
                       top_k: int = 10,
                       exclude_self: bool = True) -> List[Tuple[str, float]]:
        """
        æ ¹æ®æ¡ˆä¾‹æŸ¥æ‰¾ç›¸ä¼¼æ¡ˆä¾‹
        
        Args:
            case_data: æ¡ˆä¾‹æ•°æ®
            top_k: è¿”å›æ•°é‡
            exclude_self: æ˜¯å¦æ’é™¤è‡ªå·±
        
        Returns:
            [(case_id, score), ...]
        """
        text = self.build_case_text(case_data)
        if not text.strip():
            return []
        
        # æœç´¢æ›´å¤šä»¥ä¾¿æ’é™¤è‡ªå·±
        results = self.search(text, top_k=top_k + 5)
        
        # æ’é™¤è‡ªå·±
        if exclude_self:
            self_id = case_data.get('case_id_full') or case_data.get('case_id')
            results = [(cid, score) for cid, score in results if cid != self_id]
        
        return results[:top_k]
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_vectors': self._index.ntotal if self._index else 0,
            'dimension': self.config.dimension,
            'is_dirty': self._dirty,
            'index_file': self.index_file,
        }


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

_vector_store_instance = None

def get_vector_store(storage_path: str = None) -> VectorStore:
    """è·å–å‘é‡å­˜å‚¨å•ä¾‹"""
    global _vector_store_instance
    if _vector_store_instance is None:
        if storage_path is None:
            storage_path = "./knowledge_base/storage"
        _vector_store_instance = VectorStore(storage_path)
    return _vector_store_instance


def reset_vector_store():
    """é‡ç½®å‘é‡å­˜å‚¨å•ä¾‹"""
    global _vector_store_instance
    _vector_store_instance = None

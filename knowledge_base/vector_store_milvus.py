"""
Milvus å‘é‡å­˜å‚¨
===============
åŸºäº Milvus çš„å‘é‡æ£€ç´¢
"""

import os
import numpy as np
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

from .db_connection import connect_milvus, get_milvus_collection, MILVUS_CONFIG


@dataclass
class MilvusVectorStoreConfig:
    """å‘é‡å­˜å‚¨é…ç½®"""
    model_path: str = os.getenv("EMBEDDING_MODEL_PATH", "/data/models/bge-large-zh-v1.5")
    dimension: int = 1024       # BGE-largeç»´åº¦
    batch_size: int = 32        # ç¼–ç æ‰¹æ¬¡å¤§å°


class MilvusVectorStore:
    """
    Milvus å‘é‡å­˜å‚¨

    åŠŸèƒ½ï¼š
    - æ¡ˆä¾‹å‘é‡åŒ–å­˜å‚¨
    - ç›¸ä¼¼æ¡ˆä¾‹æ£€ç´¢
    - æ‰¹é‡é‡å»ºç´¢å¼•
    """

    def __init__(self, config: MilvusVectorStoreConfig = None):
        """åˆå§‹åŒ–å‘é‡å­˜å‚¨"""
        self.config = config or MilvusVectorStoreConfig()

        # è¿æ¥ Milvus
        connect_milvus()

        # å»¶è¿ŸåŠ è½½
        self._model = None
        self._dirty = False

    @property
    def model(self):
        """å»¶è¿ŸåŠ è½½embeddingæ¨¡å‹"""
        if self._model is None:
            print(f"ğŸ“¦ åŠ è½½Embeddingæ¨¡å‹: {self.config.model_path}")
            try:
                from sentence_transformers import SentenceTransformer
                self._model = SentenceTransformer(
                    self.config.model_path,
                    device="cpu"
                )
                print(f"   âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
            except Exception as e:
                print(f"   âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                raise
        return self._model

    @property
    def collection(self):
        """è·å– Milvus Collection"""
        return get_milvus_collection()

    @property
    def is_dirty(self):
        """ç´¢å¼•æ˜¯å¦éœ€è¦é‡å»º"""
        return self._dirty

    def mark_dirty(self):
        """æ ‡è®°ç´¢å¼•éœ€è¦é‡å»º"""
        self._dirty = True

    def build_case_text(self, case_data: Dict) -> str:
        """æ„å»ºæ¡ˆä¾‹çš„å‘é‡åŒ–æ–‡æœ¬"""
        parts = []

        # åŸºç¡€ä¿¡æ¯
        address = case_data.get('address', {})
        if isinstance(address, dict):
            address = address.get('value', '')
        parts.append(f"åœ°å€ï¼š{address}")

        # åŒºåŸŸä¿¡æ¯
        district = case_data.get('district', '')
        if district:
            parts.append(f"åŒºåŸŸï¼š{district}")

        street = case_data.get('street', '')
        if street:
            parts.append(f"è¡—é“ï¼š{street}")

        # ç”¨é€”
        usage = case_data.get('usage', '')
        if usage:
            parts.append(f"ç”¨é€”ï¼š{usage}")

        # ç»“æ„
        structure = case_data.get('structure', '')
        if structure:
            parts.append(f"ç»“æ„ï¼š{structure}")

        # é¢ç§¯
        area = case_data.get('building_area', {})
        if isinstance(area, dict):
            area = area.get('value', 0)
        if area:
            parts.append(f"å»ºç­‘é¢ç§¯ï¼š{area}å¹³æ–¹ç±³")

        # æ¥¼å±‚
        floor = case_data.get('current_floor', 0)
        total_floor = case_data.get('total_floor', 0)
        if floor and total_floor:
            parts.append(f"æ¥¼å±‚ï¼š{floor}/{total_floor}å±‚")
        elif floor:
            parts.append(f"æ¥¼å±‚ï¼š{floor}å±‚")

        # å»ºæˆå¹´ä»½
        build_year = case_data.get('build_year', 0)
        if build_year:
            parts.append(f"å»ºæˆå¹´ä»½ï¼š{build_year}å¹´")

        # æœå‘
        orientation = case_data.get('orientation', '')
        if orientation:
            parts.append(f"æœå‘ï¼š{orientation}")

        # è£…ä¿®
        decoration = case_data.get('decoration', '')
        if decoration:
            parts.append(f"è£…ä¿®ï¼š{decoration}")

        # å› ç´ æè¿°
        for factor_type in ['location_factors', 'physical_factors', 'rights_factors']:
            factors = case_data.get(factor_type, {})
            if isinstance(factors, dict):
                for factor_name, factor_data in factors.items():
                    if isinstance(factor_data, dict):
                        desc = factor_data.get('description', '')
                        if desc and len(desc) > 2:
                            parts.append(desc)

        return " ".join(parts)

    def encode(self, texts: List[str]) -> np.ndarray:
        """æ–‡æœ¬ç¼–ç ä¸ºå‘é‡"""
        if not texts:
            return np.array([])

        vectors = self.model.encode(
            texts,
            batch_size=self.config.batch_size,
            show_progress_bar=len(texts) > 10,
            normalize_embeddings=True
        )
        return vectors

    def encode_query(self, query: str) -> np.ndarray:
        """ç¼–ç æŸ¥è¯¢æ–‡æœ¬ï¼ˆæ·»åŠ BGEæŸ¥è¯¢å‰ç¼€ï¼‰"""
        query_with_prefix = f"ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š{query}"
        vector = self.model.encode(
            [query_with_prefix],
            normalize_embeddings=True
        )
        return vector

    def rebuild(self, cases: List[Dict]):
        """é‡å»ºå‘é‡ç´¢å¼•"""
        if not cases:
            print("âš ï¸ æ²¡æœ‰æ¡ˆä¾‹æ•°æ®ï¼Œè·³è¿‡å‘é‡ç´¢å¼•æ„å»º")
            self._dirty = False
            return

        print(f"ğŸ”¨ é‡å»ºå‘é‡ç´¢å¼•: {len(cases)}ä¸ªæ¡ˆä¾‹")

        # æ¸…ç©ºç°æœ‰æ•°æ®
        self.clear()

        # æ„å»ºæ•°æ®
        case_ids = []
        doc_ids = []
        report_types = []
        texts = []

        for case in cases:
            case_id = case.get('case_id_full') or case.get('case_id')
            if not case_id:
                continue

            text = self.build_case_text(case)
            if text.strip():
                case_ids.append(case_id)
                doc_ids.append(case.get('from_doc', ''))
                report_types.append(case.get('report_type', ''))
                texts.append(text)

        if not texts:
            print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ–‡æœ¬ï¼Œè·³è¿‡å‘é‡ç´¢å¼•æ„å»º")
            self._dirty = False
            return

        # ç¼–ç 
        print(f"   ç¼–ç  {len(texts)} æ¡æ–‡æœ¬...")
        vectors = self.encode(texts)

        # æ’å…¥åˆ° Milvus
        print(f"   æ’å…¥åˆ° Milvus...")
        collection = self.collection

        # åˆ†æ‰¹æ’å…¥
        batch_size = 1000
        for i in range(0, len(case_ids), batch_size):
            end = min(i + batch_size, len(case_ids))
            collection.insert([
                case_ids[i:end],
                doc_ids[i:end],
                report_types[i:end],
                vectors[i:end].tolist(),
            ])

        # åˆ·æ–°
        collection.flush()

        self._dirty = False
        print(f"   âœ“ å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ: {len(case_ids)}æ¡å‘é‡")

    def add(self, case_data: Dict):
        """æ·»åŠ å•ä¸ªæ¡ˆä¾‹åˆ°å‘é‡ç´¢å¼•"""
        case_id = case_data.get('case_id_full') or case_data.get('case_id')
        if not case_id:
            return

        text = self.build_case_text(case_data)
        if not text.strip():
            return

        vector = self.encode([text])

        collection = self.collection
        collection.insert([
            [case_id],
            [case_data.get('from_doc', '')],
            [case_data.get('report_type', '')],
            vector.tolist(),
        ])
        collection.flush()

    def delete(self, case_ids: List[str]):
        """åˆ é™¤æ¡ˆä¾‹å‘é‡"""
        if not case_ids:
            return

        collection = self.collection
        expr = f"case_id in {case_ids}"
        collection.delete(expr)
        collection.flush()

    def search(self,
               query: str,
               top_k: int = 20,
               report_type: str = None) -> List[Tuple[str, float]]:
        """å‘é‡æ£€ç´¢"""
        collection = self.collection

        # ç¡®ä¿ collection å·²åŠ è½½
        collection.load()

        # ç¼–ç æŸ¥è¯¢
        query_vector = self.encode_query(query)

        # æœç´¢å‚æ•°
        search_params = {
            "metric_type": "IP",
            "params": {"nprobe": 10},
        }

        # è¿‡æ»¤æ¡ä»¶
        expr = None
        if report_type:
            expr = f'report_type == "{report_type}"'

        # æœç´¢
        results = collection.search(
            data=query_vector.tolist(),
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            expr=expr,
            output_fields=["case_id"],
        )

        # ç»„è£…ç»“æœ
        output = []
        for hits in results:
            for hit in hits:
                output.append((hit.entity.get('case_id'), hit.score))

        return output

    def search_by_case(self,
                       case_data: Dict,
                       top_k: int = 10,
                       exclude_self: bool = True) -> List[Tuple[str, float]]:
        """æ ¹æ®æ¡ˆä¾‹æŸ¥æ‰¾ç›¸ä¼¼æ¡ˆä¾‹"""
        text = self.build_case_text(case_data)
        if not text.strip():
            return []

        # æœç´¢æ›´å¤šä»¥ä¾¿æ’é™¤è‡ªå·±
        results = self.search(text, top_k=top_k + 5)

        # æ’é™¤è‡ªå·±
        if exclude_self:
            self_id = case_data.get('case_id_full') or case_data.get('case_id')
            results = [(cid, score) for cid, score in results if cid != self_id]

        return results[:top_k]

    def clear(self):
        """æ¸…ç©ºå‘é‡ç´¢å¼•"""
        from pymilvus import utility

        collection_name = MILVUS_CONFIG['collection']
        if utility.has_collection(collection_name):
            utility.drop_collection(collection_name)

        # é‡æ–°åˆ›å»º
        self._create_collection()

    def _create_collection(self):
        """åˆ›å»º Collection"""
        from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

        collection_name = MILVUS_CONFIG['collection']

        fields = [
            FieldSchema(name="case_id", dtype=DataType.VARCHAR, max_length=64, is_primary=True),
            FieldSchema(name="doc_id", dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name="report_type", dtype=DataType.VARCHAR, max_length=50),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=self.config.dimension),
        ]

        schema = CollectionSchema(fields=fields, description="æ¡ˆä¾‹å‘é‡åº“")
        collection = Collection(name=collection_name, schema=schema)

        # åˆ›å»ºç´¢å¼•
        index_params = {
            "index_type": "IVF_FLAT",
            "metric_type": "IP",
            "params": {"nlist": 1024}
        }
        collection.create_index(field_name="embedding", index_params=index_params)

        return collection

    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        collection = self.collection
        collection.flush()

        return {
            'total_vectors': collection.num_entities,
            'dimension': self.config.dimension,
            'is_dirty': self._dirty,
            'collection': MILVUS_CONFIG['collection'],
        }


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

_vector_store_instance = None


def get_milvus_vector_store() -> MilvusVectorStore:
    """è·å–å‘é‡å­˜å‚¨å•ä¾‹"""
    global _vector_store_instance
    if _vector_store_instance is None:
        _vector_store_instance = MilvusVectorStore()
    return _vector_store_instance


def reset_milvus_vector_store():
    """é‡ç½®å‘é‡å­˜å‚¨å•ä¾‹"""
    global _vector_store_instance
    _vector_store_instance = None

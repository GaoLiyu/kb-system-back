"""
æŠ¥å‘Šå®¡æŸ¥å™¨
==========
å¯¹æ¯”çŸ¥è¯†åº“å®¡æŸ¥æ–°æ–‡ä»¶ï¼Œå‘ç°å¼‚å¸¸
"""

import os
import sys
from typing import List, Dict, Optional
from dataclasses import dataclass, field

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from extractors import extract_report
from validators import validate_report, ValidationResult
from knowledge_base import KnowledgeBaseManager, KnowledgeBaseQuery
from utils import convert_doc_to_docx, detect_report_type
from reviewer.llm_reviewer import LLMReviewer, LLMReviewResult, LLMIssue


@dataclass
class ComparisonResult:
    """å¯¹æ¯”ç»“æœ"""
    item: str
    current_value: any
    kb_min: float
    kb_max: float
    kb_avg: float
    is_abnormal: bool
    description: str = ""


@dataclass
class ReviewResult:
    """å®¡æŸ¥ç»“æœ"""
    # åŸºç¡€æ ¡éªŒ
    validation: ValidationResult = None
    
    # çŸ¥è¯†åº“å¯¹æ¯”
    comparisons: List[ComparisonResult] = field(default_factory=list)
    similar_cases: List[Dict] = field(default_factory=list)
    
    # LLMè¯­ä¹‰å®¡æŸ¥
    llm_issues: List[LLMIssue] = field(default_factory=list)
    llm_error: str = ""  # LLMè°ƒç”¨é”™è¯¯ä¿¡æ¯
    
    # ç»¼åˆè¯„ä¼°
    overall_risk: str = "low"  # low / medium / high
    summary: str = ""
    recommendations: List[str] = field(default_factory=list)


class ReportReviewer:
    """æŠ¥å‘Šå®¡æŸ¥å™¨"""
    
    def __init__(self, kb_manager: KnowledgeBaseManager, enable_llm: bool = True):
        """
        Args:
            kb_manager: çŸ¥è¯†åº“ç®¡ç†å™¨
            enable_llm: æ˜¯å¦å¯ç”¨LLMè¯­ä¹‰å®¡æŸ¥
        """
        self.kb = kb_manager
        self.query = KnowledgeBaseQuery(kb_manager)
        self.enable_llm = enable_llm
        self.llm_reviewer = LLMReviewer() if enable_llm else None
    
    def review(self, doc_path: str, verbose: bool = True) -> ReviewResult:
        """
        å®¡æŸ¥æŠ¥å‘Š
        
        Args:
            doc_path: æ–‡æ¡£è·¯å¾„
            verbose: æ˜¯å¦æ‰“å°è¯¦æƒ…
        
        Returns:
            ReviewResult
        """
        if verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ” å®¡æŸ¥æŠ¥å‘Š: {os.path.basename(doc_path)}")
            print(f"{'='*60}")
        
        # å¤„ç†docæ–‡ä»¶
        if doc_path.lower().endswith('.doc'):
            doc_path = convert_doc_to_docx(doc_path)
        
        # æ£€æµ‹ç±»å‹
        report_type = detect_report_type(doc_path)
        
        # æå–æ•°æ®
        result = extract_report(doc_path)
        
        # 1. åŸºç¡€æ ¡éªŒ
        validation = validate_report(result)
        if verbose:
            print(f"\nğŸ“‹ åŸºç¡€æ ¡éªŒ: {validation.summary}")
        
        # 2. ä¸çŸ¥è¯†åº“å¯¹æ¯”
        comparisons = self._compare_with_kb(result, report_type)
        if verbose and comparisons:
            abnormal = [c for c in comparisons if c.is_abnormal]
            print(f"ğŸ“Š çŸ¥è¯†åº“å¯¹æ¯”: {len(abnormal)} é¡¹å¼‚å¸¸")
        
        # 3. æŸ¥æ‰¾ç›¸ä¼¼æ¡ˆä¾‹
        similar_cases = self._find_similar(result, report_type)
        if verbose:
            print(f"ğŸ” ç›¸ä¼¼æ¡ˆä¾‹: {len(similar_cases)} ä¸ª")
        
        # 4. LLMè¯­ä¹‰å®¡æŸ¥
        llm_issues = []
        llm_error = ""
        if self.enable_llm and self.llm_reviewer and self.llm_reviewer.is_available():
            if verbose:
                print(f"ğŸ¤– LLMè¯­ä¹‰å®¡æŸ¥...")
            llm_result = self.llm_reviewer.review(result, report_type)
            llm_issues = llm_result.issues
            llm_error = llm_result.error_message
            if verbose:
                print(f"   å‘ç° {len(llm_issues)} ä¸ªè¯­ä¹‰é—®é¢˜")
        elif verbose and self.enable_llm:
            print(f"ğŸ¤– LLMæœªé…ç½®ï¼Œè·³è¿‡è¯­ä¹‰å®¡æŸ¥")
        
        # 5. ç»¼åˆè¯„ä¼°
        review_result = ReviewResult(
            validation=validation,
            comparisons=comparisons,
            similar_cases=similar_cases,
            llm_issues=llm_issues,
            llm_error=llm_error,
        )
        
        self._evaluate(review_result)
        
        if verbose:
            self._print_result(review_result)
        
        return review_result
    
    def _compare_with_kb(self, result, report_type: str) -> List[ComparisonResult]:
        """ä¸çŸ¥è¯†åº“å¯¹æ¯”"""
        comparisons = []
        
        # è·å–çŸ¥è¯†åº“ç»Ÿè®¡
        price_stats = self.query.get_price_range(report_type)
        area_stats = self.query.get_area_range(report_type)
        correction_stats = self.query.get_correction_stats(report_type)
        
        # å¦‚æœçŸ¥è¯†åº“æ²¡æœ‰æ•°æ®ï¼Œè·³è¿‡å¯¹æ¯”
        if price_stats['count'] == 0:
            return comparisons
        
        # å¯¹æ¯”æ¯ä¸ªæ¡ˆä¾‹
        for case in result.cases:
            # ä»·æ ¼å¯¹æ¯”
            price = None
            if hasattr(case, 'transaction_price') and case.transaction_price.value:
                price = case.transaction_price.value
            elif hasattr(case, 'rental_price') and case.rental_price.value:
                price = case.rental_price.value
            elif hasattr(case, 'final_price') and case.final_price.value:
                price = case.final_price.value
            
            if price and price_stats['count'] > 0:
                is_abnormal = price < price_stats['min'] * 0.5 or price > price_stats['max'] * 1.5
                comparisons.append(ComparisonResult(
                    item=f"å®ä¾‹{case.case_id}ä»·æ ¼",
                    current_value=price,
                    kb_min=price_stats['min'],
                    kb_max=price_stats['max'],
                    kb_avg=price_stats['avg'],
                    is_abnormal=is_abnormal,
                    description="ä»·æ ¼æ˜æ˜¾åç¦»çŸ¥è¯†åº“èŒƒå›´" if is_abnormal else "",
                ))
            
            # ä¿®æ­£ç³»æ•°å¯¹æ¯”
            for name, field in [
                ('åŒºä½ä¿®æ­£', 'location_correction'),
                ('å®ç‰©ä¿®æ­£', 'physical_correction'),
            ]:
                if hasattr(case, field):
                    val = getattr(case, field).value
                    key = field.replace('_correction', '')
                    stats = correction_stats.get(key, {})
                    
                    if val and stats.get('count', 0) > 0:
                        is_abnormal = val < stats['min'] * 0.8 or val > stats['max'] * 1.2
                        comparisons.append(ComparisonResult(
                            item=f"å®ä¾‹{case.case_id}{name}",
                            current_value=val,
                            kb_min=stats['min'],
                            kb_max=stats['max'],
                            kb_avg=stats['avg'],
                            is_abnormal=is_abnormal,
                            description=f"{name}ç³»æ•°åç¦»çŸ¥è¯†åº“èŒƒå›´" if is_abnormal else "",
                        ))
        
        return comparisons
    
    def _find_similar(self, result, report_type: str) -> List[Dict]:
        """æŸ¥æ‰¾ç›¸ä¼¼æ¡ˆä¾‹"""
        # è·å–ä¼°ä»·å¯¹è±¡ä¿¡æ¯
        address = result.subject.address.value or ""
        area = result.subject.building_area.value or 0
        
        # è·å–ä»·æ ¼å‚è€ƒ
        price = 0
        if hasattr(result, 'final_unit_price') and result.final_unit_price.value:
            price = result.final_unit_price.value
        
        # æŸ¥æ‰¾ç›¸ä¼¼æ¡ˆä¾‹
        similar = self.query.find_similar_cases(
            address=address,
            area=area,
            price=price,
            report_type=report_type,
            top_k=5
        )
        
        return [case for case, score in similar]
    
    def _evaluate(self, review_result: ReviewResult):
        """ç»¼åˆè¯„ä¼°"""
        # è®¡ç®—é£é™©ç­‰çº§
        error_count = len([i for i in review_result.validation.issues if i.level == 'error'])
        warning_count = len([i for i in review_result.validation.issues if i.level == 'warning'])
        abnormal_count = len([c for c in review_result.comparisons if c.is_abnormal])
        llm_critical = len([i for i in review_result.llm_issues if i.severity == 'critical'])
        llm_major = len([i for i in review_result.llm_issues if i.severity == 'major'])
        
        if error_count > 0 or abnormal_count > 2 or llm_critical > 0:
            review_result.overall_risk = 'high'
        elif warning_count > 3 or abnormal_count > 0 or llm_major > 0:
            review_result.overall_risk = 'medium'
        else:
            review_result.overall_risk = 'low'
        
        # ç”Ÿæˆæ‘˜è¦
        parts = []
        if error_count > 0:
            parts.append(f"{error_count}ä¸ªä¸¥é‡é”™è¯¯")
        if warning_count > 0:
            parts.append(f"{warning_count}ä¸ªè­¦å‘Š")
        if abnormal_count > 0:
            parts.append(f"{abnormal_count}é¡¹æ•°æ®å¼‚å¸¸")
        if len(review_result.llm_issues) > 0:
            parts.append(f"{len(review_result.llm_issues)}ä¸ªè¯­ä¹‰é—®é¢˜")
        
        if parts:
            review_result.summary = f"å‘ç° " + "ï¼Œ".join(parts)
        else:
            review_result.summary = "æœªå‘ç°æ˜æ˜¾é—®é¢˜"
        
        # ç”Ÿæˆå»ºè®®
        if error_count > 0:
            review_result.recommendations.append("è¯·å…ˆä¿®æ­£æ•°æ®å®Œæ•´æ€§é—®é¢˜")
        if abnormal_count > 0:
            review_result.recommendations.append("è¯·æ ¸å®åç¦»çŸ¥è¯†åº“èŒƒå›´çš„æ•°æ®")
        if len(review_result.llm_issues) > 0:
            review_result.recommendations.append("è¯·å…³æ³¨LLMå‘ç°çš„è¯­ä¹‰é—®é¢˜")
        if len(review_result.similar_cases) > 0:
            review_result.recommendations.append("å¯å‚è€ƒç›¸ä¼¼æ¡ˆä¾‹è¿›è¡Œæ ¸å¯¹")
    
    def _print_result(self, review_result: ReviewResult):
        """æ‰“å°ç»“æœ"""
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ å®¡æŸ¥ç»“æœ")
        print(f"{'='*60}")
        
        # é£é™©ç­‰çº§
        risk_icon = {"low": "ğŸŸ¢", "medium": "ğŸŸ¡", "high": "ğŸ”´"}
        print(f"é£é™©ç­‰çº§: {risk_icon.get(review_result.overall_risk, '')} {review_result.overall_risk}")
        print(f"æ‘˜è¦: {review_result.summary}")
        
        # åŸºç¡€æ ¡éªŒé—®é¢˜
        if review_result.validation.issues:
            print(f"\nåŸºç¡€æ ¡éªŒé—®é¢˜ ({len(review_result.validation.issues)} ä¸ª):")
            for i, issue in enumerate(review_result.validation.issues, 1):
                icon = "âŒ" if issue.level == 'error' else "âš ï¸"
                print(f"  {i}. {icon} [{issue.category}] {issue.description}")
                if issue.position:
                    print(f"      ğŸ“ ä½ç½®: è¡¨æ ¼{issue.position.get('table', 0)+1}, ç¬¬{issue.position.get('row', 0)+1}è¡Œ")
        
        # å…¬å¼éªŒè¯
        if review_result.validation.formula_checks:
            print(f"\nå…¬å¼éªŒè¯ ({len(review_result.validation.formula_checks)} é¡¹):")
            for fc in review_result.validation.formula_checks:
                status = "âœ“" if fc.is_valid else "âœ—"
                print(f"  {status} å®ä¾‹{fc.case_id}: æœŸæœ›{fc.expected:.0f} å®é™…{fc.actual:.0f} å·®å¼‚{fc.difference:.0f}")
        
        # çŸ¥è¯†åº“å¯¹æ¯”
        abnormal = [c for c in review_result.comparisons if c.is_abnormal]
        if abnormal:
            print(f"\nçŸ¥è¯†åº“å¯¹æ¯”å¼‚å¸¸ ({len(abnormal)} é¡¹):")
            for c in abnormal:
                print(f"  âš ï¸ {c.item}: {c.current_value:.2f}")
                print(f"      çŸ¥è¯†åº“èŒƒå›´: {c.kb_min:.2f} ~ {c.kb_max:.2f} (å¹³å‡: {c.kb_avg:.2f})")
        
        # LLMè¯­ä¹‰å®¡æŸ¥é—®é¢˜
        if review_result.llm_issues:
            print(f"\nLLMè¯­ä¹‰å®¡æŸ¥ ({len(review_result.llm_issues)} ä¸ªé—®é¢˜):")
            for i, issue in enumerate(review_result.llm_issues, 1):
                severity_icon = {"critical": "ğŸ”´", "major": "ğŸŸ ", "minor": "ğŸŸ¡"}.get(issue.severity, "âšª")
                print(f"  {i}. {severity_icon} [{issue.type}] {issue.description}")
                if issue.case_id:
                    print(f"      æ¶‰åŠ: å®ä¾‹{issue.case_id}")
                if issue.factor:
                    print(f"      å› ç´ : {issue.factor}")
                if issue.suggestion:
                    print(f"      å»ºè®®: {issue.suggestion}")
        
        if review_result.llm_error:
            print(f"\nâš ï¸ LLMå®¡æŸ¥å¼‚å¸¸: {review_result.llm_error}")
        
        # ç›¸ä¼¼æ¡ˆä¾‹
        if review_result.similar_cases:
            print(f"\nç›¸ä¼¼æ¡ˆä¾‹å‚è€ƒ ({len(review_result.similar_cases)} ä¸ª):")
            for case in review_result.similar_cases[:3]:
                addr = case.get('address', {}).get('value', 'æœªçŸ¥')
                price = case.get('transaction_price', {}).get('value') or \
                        case.get('rental_price', {}).get('value') or \
                        case.get('final_price', {}).get('value') or 0
                print(f"  - {addr}: {price:.0f}å…ƒ/ã¡")
        
        # å»ºè®®
        if review_result.recommendations:
            print(f"\nğŸ’¡ å»ºè®®:")
            for rec in review_result.recommendations:
                print(f"  â€¢ {rec}")


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def review_report(doc_path: str, kb_path: str = "./knowledge_base/storage", verbose: bool = True) -> ReviewResult:
    """å®¡æŸ¥æŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°"""
    kb = KnowledgeBaseManager(kb_path)
    reviewer = ReportReviewer(kb)
    return reviewer.review(doc_path, verbose)
